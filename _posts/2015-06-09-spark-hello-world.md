---
layout: post
title: "Spark Hello World"
description: "Spark intro part 2"
category: [bigdata]
tags: [big data, spark, hello world, recommendations]
---

<ol>
<li>First, you need to go to the [Spark Downloads page](http://spark.apache.org/downloads.html) and then select the Spark release you want to install and the package type (you could choose to build it from source for various Hadoop versions or select a version pre built for a specific Hadoop version)</li>
<li>Next, unzip the file and move it to a convenient folder like (/home/username/Programming) or anything you are comfortable with</li>
<li>Spark runs on both Windows and Unix perfectly well. The only requirement in either case is that you need to have Java installed and in your system path. I can describe the steps to set the JAVA_HOME c</li>
</ol>

